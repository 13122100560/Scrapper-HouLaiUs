{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取豆瓣《后来的我们》热门评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置爬虫的`cookie`和`header`,这部分需要登录豆瓣的个人账户后从*Chrome*的debugger里获取。刚开始的时候不加入`cookie`很快就被豆瓣封掉了，后来加入之后解决了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://movie.douban.com/subject/26683723/comments?status=P'\n",
    "\n",
    "cookies = {\n",
    "    'Cookie':'\"ll=\"118281\"; bid=RXLLSV3Lpl8; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1525677293%2C%22https%3A%2F%2Fwww.baidu.com%2Fs%3Fie%3Dutf-8%26f%3D8%26rsv_bp%3D0%26rsv_idx%3D1%26tn%3Dbaidu%26wd%3Ddouban%26rsv_pq%3Dec71a7d500054ab9%26rsv_t%3Daea9JlVdYh1gD%252BGRz5EBNm%252FpcUlfXaX4KGe1v0B%252FlIFjMUTaJc95TIgL9nA%26rqlang%3Dcn%26rsv_enter%3D1%26rsv_sug3%3D6%26rsv_sug1%3D6%26rsv_sug7%3D100%26rsv_sug2%3D0%26inputT%3D1530%26rsv_sug4%3D1530%22%5D; _pk_id.100001.4cf6=e4478045f12b58d7.1525677293.1.1525677596.1525677293.; _pk_ses.100001.4cf6=*; __yadk_uid=sG0bTgzZcP364YKhAUooIpRTIZSaDYwU; __utma=30149280.1936213219.1525677295.1525677295.1525677295.1; __utmb=30149280.0.10.1525677295; __utmc=30149280; __utmz=30149280.1525677295.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utma=223695111.788299203.1525677295.1525677295.1525677295.1; __utmb=223695111.0.10.1525677295; __utmc=223695111; __utmz=223695111.1525677295.1.1.utmcsr=baidu|utmccn=(organic)|utmcmd=organic|utmctr=douban; _vwo_uuid_v2=DC384E6C9A270E7570AA1C544579FBD63|b1ff83255465a52a2ca8a027f6fb3249; ps=y; ue=\"lixiaohuipb@163.com\"; dbcl2=\"173117659:E2lDtbaaY9I\"; ck=3lvF; push_noty_num=0; push_doumail_num=0\"'\n",
    "}\n",
    "headers = {\n",
    "    'User-Agent':\"Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0\"\n",
    "}\n",
    "sess = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载代理IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('proxies.csv')\n",
    "select_columns = ['ip', 'port', 'type']\n",
    "proxies = df[select_columns]\n",
    "proxies['concated'] = proxies['type'].astype(str) + \"://\" + proxies['ip'].astype(str) +\":\" + proxies['port'].astype(str)\n",
    "def pick_proxy():\n",
    "    proxy_dict = {}\n",
    "    index = np.random.choice(proxies.shape[0])\n",
    "    proxy = proxies['concated'][index]\n",
    "    head = proxies.loc[index]['type']\n",
    "    proxy_dict[head] = proxy\n",
    "    return proxy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取网页内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    response = sess.get(url, proxies = pick_proxy(),headers = headers, cookies = cookies, verify=False)\n",
    "    content = response.text\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'html5lib')\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        print(content)\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取包含评论的DIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_result(soup):\n",
    "    result = soup.findAll(class_='comment')\n",
    "    while result == 0:\n",
    "        break\n",
    "    print('We\"ve found {} results in this page'.format(len(result)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取评论字段并保存到csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract = lambda pattern, string: re.findall(pattern, string)\n",
    "# comment = [extract(commentPatter,  str(res).replace(\"\\n\", '').replace(\" \", '')) for res in result]\n",
    "# votes = [extract(votesPattern,  str(res).replace(\"\\n\", '').replace(\" \", '')) for res in result]\n",
    "# ratings = [extract(ratingsPattern,  str(res).replace(\"\\n\", '').replace(\" \", '')) for res in result]\n",
    "# print(len(comment), len(votes), len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "commentPatter = re.compile(r'<divclass=\"comment\">.*?<pclass=\"\">(.*?)</p>')\n",
    "votesPattern = re.compile(r'<spanclass=\"votes\">(.*?)</span>')\n",
    "ratingsPattern = re.compile(r'<spanclass=\"allstar.*?rating\"title=\"(.*?)\"></span>')\n",
    "timePattern = re.compile(r'<spanclass=\"comment-time\".*?>(.*?)</span>')\n",
    "def extract_comment(result):\n",
    "    commentList = []\n",
    "    for res in result:\n",
    "        com = str(res).replace(\"\\n\", '').replace(\" \", '')\n",
    "        comment = re.findall(commentPatter, com)\n",
    "        votes = re.findall(votesPattern, com)\n",
    "        ratings = re.findall(ratingsPattern, com)\n",
    "        time = re.findall(timePattern, com)\n",
    "        ratings = ratings if ratings else [\"None\"]\n",
    "        commentList.append((comment[0], votes[0], ratings[0], time[0]))\n",
    "    df = pd.DataFrame.from_records(commentList)\n",
    "    write2csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入到csv文件函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2csv(df):\n",
    "    df.to_csv('comment.csv',mode='a+', header=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主爬虫函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapper(url):\n",
    "    soup = get_content(url)\n",
    "    result = find_result(soup)\n",
    "    extract_comment(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=0&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=20&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=40&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=60&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=80&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=100&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=120&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=140&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=160&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=180&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=200&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=220&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=240&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=260&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=280&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=300&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=320&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=340&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=360&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=380&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=400&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=420&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=440&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=460&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n",
      "I am scrapping : https://movie.douban.com/subject/26683723/comments?start=480&limit=20&sort=new_score&status=P&percent_type=\n",
      "We\"ve found 20 results in this page\n"
     ]
    }
   ],
   "source": [
    "commentCount = 500\n",
    "prefix = 'https://movie.douban.com/subject/26683723/comments?start={}&limit=20&sort=new_score&status=P&percent_type='\n",
    "for i in np.arange(0,commentCount,20):\n",
    "    time.sleep(np.random.rand()*5)\n",
    "    url = prefix.format(i)\n",
    "    print(\"I am scrapping : \" + url)\n",
    "    scrapper(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
